{
  "createdAt": "2025-08-30T19:57:08.538Z",
  "updatedAt": "2025-09-21T05:16:04.521Z",
  "id": "XJeicUzVaGNb8gsB",
  "name": "COORDINATION - Democratic Collaboration - OpenRouter - Production",
  "active": true,
  "isArchived": false,
  "nodes": [
    {
      "parameters": {
        "path": "llm-collaboration",
        "options": {}
      },
      "id": "webhook-trigger",
      "name": "Webhook Trigger",
      "type": "n8n-nodes-base.webhook",
      "typeVersion": 1,
      "position": [
        128,
        304
      ],
      "webhookId": "llm-collaboration-webhook"
    },
    {
      "parameters": {
        "functionCode": "// Democratic LLM Selection Algorithm\nconst task = $json.task;\nconst availableModels = $json.collaboration_context.available_models;\nconst budgetConstraints = $json.collaboration_context.budget_constraints;\n\n// Model configurations with OpenRouter IDs\nconst models = {\n  'claude-sonnet': {\n    platform: 'anthropic',\n    openrouter_id: 'anthropic/claude-3.5-sonnet',\n    cost_per_token: 0.000003,\n    specialization: 'strategic_analysis',\n    strengths: ['reasoning', 'analysis', 'coding', 'writing']\n  },\n  'gpt-4o': {\n    platform: 'openai', \n    openrouter_id: 'openai/gpt-4o',\n    cost_per_token: 0.000005,\n    specialization: 'research',\n    strengths: ['multimodal', 'creativity', 'general_purpose']\n  },\n  'gemini-pro': {\n    platform: 'google',\n    openrouter_id: 'google/gemini-pro-1.5',\n    cost_per_token: 0.000002,\n    specialization: 'optimization', \n    strengths: ['code_analysis', 'performance', 'efficiency']\n  },\n  'llama-3': {\n    platform: 'meta',\n    openrouter_id: 'meta-llama/llama-3-70b-instruct',\n    cost_per_token: 0.000001,\n    specialization: 'code_implementation',\n    strengths: ['open_source', 'cost_effective', 'coding']\n  }\n};\n\n// Task-model affinity scoring\nconst taskAffinities = {\n  'code_implementation': {\n    'llama-3': 0.95,\n    'claude-sonnet': 0.85,\n    'gemini-pro': 0.80,\n    'gpt-4o': 0.70\n  },\n  'strategic_analysis': {\n    'claude-sonnet': 0.98,\n    'gpt-4o': 0.90,\n    'gemini-pro': 0.75,\n    'llama-3': 0.65\n  },\n  'research': {\n    'gpt-4o': 0.95,\n    'claude-sonnet': 0.85,\n    'gemini-pro': 0.75,\n    'llama-3': 0.60\n  },\n  'optimization': {\n    'gemini-pro': 0.95,\n    'llama-3': 0.85,\n    'claude-sonnet': 0.80,\n    'gpt-4o': 0.75\n  }\n};\n\n// Democratic selection algorithm\nfunction selectBestModel(task, availableModels) {\n  const taskType = task.type;\n  const complexity = task.complexity;\n  \n  let scores = {};\n  \n  // Calculate base scores from task affinity\n  if (taskAffinities[taskType]) {\n    scores = { ...taskAffinities[taskType] };\n  } else {\n    // Default scoring for unknown task types\n    availableModels.forEach(model => {\n      scores[model] = 0.7; // neutral score\n    });\n  }\n  \n  // Adjust for complexity\n  const complexityMultiplier = {\n    'low': 0.9,\n    'medium': 1.0,\n    'high': 1.1\n  }[complexity] || 1.0;\n  \n  // Apply complexity adjustment and cost considerations\n  Object.keys(scores).forEach(modelName => {\n    if (models[modelName]) {\n      scores[modelName] *= complexityMultiplier;\n      \n      // Cost efficiency bonus for budget-conscious selections\n      const costEfficiency = 1 / (models[modelName].cost_per_token * 1000000); // normalize\n      scores[modelName] += costEfficiency * 0.1; // small cost bonus\n    }\n  });\n  \n  // Find the best model\n  const bestModel = Object.entries(scores)\n    .filter(([model]) => availableModels.includes(model))\n    .sort(([,a], [,b]) => b - a)[0];\n  \n  return {\n    selected_model: bestModel[0],\n    confidence: bestModel[1],\n    all_scores: scores,\n    model_config: models[bestModel[0]]\n  };\n}\n\n// Perform selection\nconst selection = selectBestModel(task, availableModels);\n\n// Estimate cost\nconst estimatedTokens = {\n  'low': 500,\n  'medium': 1500,\n  'high': 3000\n}[task.complexity] || 1500;\n\nconst estimatedCost = estimatedTokens * selection.model_config.cost_per_token;\n\nreturn [{\n  collaboration_id: $json.collaboration_id,\n  session_id: $json.session_id,\n  selected_model: selection.selected_model,\n  confidence_score: selection.confidence,\n  model_config: selection.model_config,\n  estimated_cost: estimatedCost,\n  estimated_tokens: estimatedTokens,\n  routing_decision: {\n    primary_model: selection.selected_model,\n    fallback_models: Object.entries(selection.all_scores)\n      .filter(([model]) => model !== selection.selected_model && availableModels.includes(model))\n      .sort(([,a], [,b]) => b - a)\n      .slice(0, 2)\n      .map(([model]) => model),\n    democratic_scores: selection.all_scores\n  },\n  task: task\n}];"
      },
      "id": "democratic-router",
      "name": "Democratic LLM Router",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        352,
        304
      ]
    },
    {
      "parameters": {},
      "id": "model-router",
      "name": "Model Router",
      "type": "n8n-nodes-base.switch",
      "typeVersion": 2,
      "position": [
        560,
        304
      ]
    },
    {
      "parameters": {
        "url": "https://api.anthropic.com/v1/messages",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "x-api-key",
              "value": "={{$env.CLAUDE_API_KEY}}"
            },
            {
              "name": "anthropic-version",
              "value": "2023-06-01"
            },
            {
              "name": "content-type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "model",
              "value": "claude-3-5-sonnet-20241022"
            },
            {
              "name": "max_tokens",
              "value": "={{$json.estimated_tokens}}"
            },
            {
              "name": "messages",
              "value": "=[{\"role\": \"user\", \"content\": $json.task.description}]"
            }
          ]
        },
        "options": {}
      },
      "id": "claude-endpoint",
      "name": "Claude API",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        784,
        208
      ]
    },
    {
      "parameters": {
        "url": "https://openrouter.ai/api/v1/chat/completions",
        "authentication": "genericCredentialType",
        "genericAuthType": "httpHeaderAuth",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Authorization",
              "value": "Bearer {{$env.OPENROUTER_API_KEY}}"
            },
            {
              "name": "Content-Type",
              "value": "application/json"
            },
            {
              "name": "HTTP-Referer",
              "value": "https://n8n.pbradygeorgen.com"
            },
            {
              "name": "X-Title",
              "value": "LLM Democratic Collaboration"
            }
          ]
        },
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "model",
              "value": "={{$json.model_config.openrouter_id}}"
            },
            {
              "name": "max_tokens",
              "value": "={{$json.estimated_tokens}}"
            },
            {
              "name": "messages",
              "value": "=[{\"role\": \"user\", \"content\": $json.task.description}]"
            },
            {
              "name": "temperature",
              "value": 0.7
            }
          ]
        },
        "options": {}
      },
      "id": "openrouter-endpoint",
      "name": "OpenRouter API",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        784,
        400
      ]
    },
    {
      "parameters": {
        "functionCode": "// Response Aggregation and Quality Assessment\nconst input = $input.all();\nconst originalData = input[0]; // Contains our routing decision\nconst llmResponse = input[0]; // Contains the LLM response\n\n// Parse the LLM response based on the platform\nlet parsedResponse;\nlet usage = {};\n\nif (originalData.selected_model === 'claude-sonnet') {\n  // Claude API response format\n  parsedResponse = {\n    content: llmResponse.content?.[0]?.text || llmResponse.text || 'No response',\n    model: llmResponse.model || 'claude-3-5-sonnet-20241022',\n    usage: llmResponse.usage || {}\n  };\n} else {\n  // OpenRouter API response format (OpenAI compatible)\n  parsedResponse = {\n    content: llmResponse.choices?.[0]?.message?.content || 'No response',\n    model: llmResponse.model || originalData.model_config.openrouter_id,\n    usage: llmResponse.usage || {}\n  };\n}\n\n// Calculate actual cost based on usage\nconst actualTokens = parsedResponse.usage.total_tokens || originalData.estimated_tokens;\nconst actualCost = actualTokens * originalData.model_config.cost_per_token;\n\n// Quality assessment\nconst qualityMetrics = {\n  response_length: parsedResponse.content.length,\n  estimated_vs_actual_tokens: {\n    estimated: originalData.estimated_tokens,\n    actual: actualTokens,\n    accuracy: Math.abs(1 - (actualTokens / originalData.estimated_tokens))\n  },\n  cost_efficiency: {\n    estimated: originalData.estimated_cost,\n    actual: actualCost,\n    savings: originalData.estimated_cost - actualCost\n  },\n  model_confidence: originalData.confidence_score\n};\n\n// Final collaboration result\nconst collaborationResult = {\n  collaboration_id: originalData.collaboration_id,\n  session_id: originalData.session_id,\n  timestamp: new Date().toISOString(),\n  \n  // Democratic selection results\n  democratic_selection: {\n    selected_model: originalData.selected_model,\n    confidence_score: originalData.confidence_score,\n    routing_decision: originalData.routing_decision,\n    selection_rationale: `Selected ${originalData.selected_model} with ${(originalData.confidence_score * 100).toFixed(1)}% confidence for ${originalData.task.type} task`\n  },\n  \n  // LLM Response\n  llm_response: {\n    content: parsedResponse.content,\n    model: parsedResponse.model,\n    platform: originalData.model_config.platform\n  },\n  \n  // Cost and usage analytics\n  analytics: {\n    usage: parsedResponse.usage,\n    cost_analysis: qualityMetrics.cost_efficiency,\n    token_prediction_accuracy: qualityMetrics.estimated_vs_actual_tokens.accuracy,\n    quality_score: Math.min(1.0, originalData.confidence_score * (1 - qualityMetrics.estimated_vs_actual_tokens.accuracy * 0.1))\n  },\n  \n  // Task metadata\n  task_metadata: {\n    task_id: originalData.task.task_id,\n    task_type: originalData.task.type,\n    complexity: originalData.task.complexity,\n    completion_time: new Date().toISOString()\n  },\n  \n  // System metadata for learning\n  system_metadata: {\n    n8n_workflow: 'LLM_Democratic_Collaboration',\n    integration_version: '1.0.0',\n    collaboration_mode: 'democratic_selection',\n    success: true\n  }\n};\n\nreturn [collaborationResult];"
      },
      "id": "response-aggregator",
      "name": "Response Aggregator",
      "type": "n8n-nodes-base.function",
      "typeVersion": 1,
      "position": [
        1008,
        304
      ]
    },
    {
      "parameters": {
        "url": "={{ $env.N8N_BASE_URL }}/webhook/collaboration-complete",
        "sendHeaders": true,
        "headerParameters": {
          "parameters": [
            {
              "name": "Content-Type",
              "value": "application/json"
            }
          ]
        },
        "sendBody": true,
        "bodyParameters": {
          "parameters": [
            {
              "name": "collaboration_result",
              "value": "={{$json}}"
            }
          ]
        },
        "options": {}
      },
      "id": "result-webhook",
      "name": "Result Webhook",
      "type": "n8n-nodes-base.httpRequest",
      "typeVersion": 4.2,
      "position": [
        1232,
        304
      ]
    }
  ],
  "connections": {
    "Webhook Trigger": {
      "main": [
        [
          {
            "node": "Democratic LLM Router",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Democratic LLM Router": {
      "main": [
        [
          {
            "node": "Model Router",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Model Router": {
      "main": [
        [
          {
            "node": "Claude API",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "OpenRouter API",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "OpenRouter API",
            "type": "main",
            "index": 0
          }
        ],
        [
          {
            "node": "OpenRouter API",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Claude API": {
      "main": [
        [
          {
            "node": "Response Aggregator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "OpenRouter API": {
      "main": [
        [
          {
            "node": "Response Aggregator",
            "type": "main",
            "index": 0
          }
        ]
      ]
    },
    "Response Aggregator": {
      "main": [
        [
          {
            "node": "Result Webhook",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  },
  "settings": {
    "executionOrder": "v1"
  },
  "staticData": null,
  "meta": null,
  "pinData": {},
  "versionId": "659d175e-d7d4-4a10-bcbe-ceefa63a56c1",
  "triggerCount": 1,
  "shared": [
    {
      "createdAt": "2025-08-30T19:57:08.542Z",
      "updatedAt": "2025-08-30T19:57:08.542Z",
      "role": "workflow:owner",
      "workflowId": "XJeicUzVaGNb8gsB",
      "projectId": "4Pe2tfKPH8e3rX41"
    }
  ],
  "tags": []
}